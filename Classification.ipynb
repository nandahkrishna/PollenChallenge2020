{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pollen Challenge ICPR 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Class 1: 1567 Images\n",
    "* Class 2: 773 Images\n",
    "* Class 3: 8216 Images\n",
    "* Class 4: 724 Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - Normal images with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = []\n",
    "image_labels = []\n",
    "for i in range(1, 5):\n",
    "    input_dir = f\"./train/images/{i}/train_SEGM/\"\n",
    "    images = os.listdir(input_dir)\n",
    "    for j in range(len(images)):\n",
    "        if images[j].split(\".\")[-1] == \"png\":\n",
    "            image_names.append(input_dir + images[j])\n",
    "            image_labels.append(i - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are 84 x 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (96, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in image_names:\n",
    "    if image.split('.')[-1] == 'png':\n",
    "        images.append(cv2.resize(cv2.imread(image, cv2.IMREAD_UNCHANGED), dim, interpolation=cv2.INTER_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images).astype(np.float32)\n",
    "images = images / 255.\n",
    "image_labels = np.array(image_labels)\n",
    "image_labels = to_categorical(image_labels, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.VGG16(include_top=False, input_shape=(96, 96, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "flatten_out = Flatten()(model.output)\n",
    "class_out = Dense(512, activation='relu')(flatten_out)\n",
    "class_out = Dropout(0.5)(class_out)\n",
    "output = Dense(4, activation='softmax')(class_out)\n",
    "model = keras.Model(inputs=model.inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(images, image_labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(np.argmax(y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(np.argmax(y_val, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_val, y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"vgg16_normalised_96_noaug_lastconvtop_10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_val.astype(np.float32)), axis=1)\n",
    "y_val_ = np.argmax(y_val, axis=1)\n",
    "print(classification_report(y_val_, y_pred))\n",
    "print(confusion_matrix(y_val_, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - Segmented images with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = []\n",
    "image_masks = []\n",
    "image_labels = []\n",
    "for i in range(1, 5):\n",
    "    input_dir = f\"./train/images/{i}/train_OBJ/\"\n",
    "    mask_dir = f\"./train/images/{i}/train_MASK/\"\n",
    "    images = os.listdir(input_dir)\n",
    "    for j in range(len(images)):\n",
    "        if images[j].split(\".\")[-1] == \"png\":\n",
    "            image_names.append(input_dir + images[j])\n",
    "            image_masks.append(mask_dir + images[j].replace(\"OBJ\", \"MASK\"))\n",
    "            image_labels.append(i - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in tqdm(range(len(image_names))):\n",
    "    if image_names[i].split('.')[-1] == 'png':\n",
    "        img = cv2.imread(image_names[i], cv2.IMREAD_UNCHANGED)\n",
    "        m = cv2.imread(image_masks[i], cv2.IMREAD_GRAYSCALE)\n",
    "        res = cv2.bitwise_and(img, img, mask=m)\n",
    "        images.append(cv2.resize(res, dim, interpolation=cv2.INTER_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images).astype(np.float32)\n",
    "images = images / 255.\n",
    "image_labels = np.array(image_labels)\n",
    "image_labels = to_categorical(image_labels, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.VGG16(include_top=False, input_shape=(96, 96, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "flatten_out = Flatten()(model.output)\n",
    "class_out = Dense(512, activation='relu')(flatten_out)\n",
    "class_out = Dropout(0.5)(class_out)\n",
    "output = Dense(4, activation='softmax')(class_out)\n",
    "model = keras.Model(inputs=model.inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(images, image_labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(np.argmax(y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(np.argmax(y_val, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_val, y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"vgg16_segmented_96_noaug_lastconvtop_10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_val.astype(np.float32)), axis=1)\n",
    "y_val_ = np.argmax(y_val, axis=1)\n",
    "print(classification_report(y_val_, y_pred))\n",
    "print(confusion_matrix(y_val_, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_names = []\n",
    "test_input_dir = f\"./test/images/\"\n",
    "test_images = os.listdir(test_input_dir)\n",
    "for j in range(len(test_images)):\n",
    "    if test_images[j].split(\".\")[-1] == \"png\":\n",
    "        test_image_names.append(test_input_dir + test_images[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for test_image in test_image_names:\n",
    "    if test_image.split('.')[-1] == 'png':\n",
    "        test_images.append(cv2.resize(cv2.imread(test_image, cv2.IMREAD_UNCHANGED),\n",
    "                                      dim, interpolation=cv2.INTER_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.array(test_images).astype(np.float32)\n",
    "test_images = test_images / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"vgg16_normalised_96_noaug_lastconvtop_10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.argmax(model.predict(test_images), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = []\n",
    "for i in range(len(test_image_names)):\n",
    "    submission.append({\"Filename\": \"{}\".format(test_image_names[i].split(\"/\")[-1]),\n",
    "                       \"Class\": str(test_pred[i] + 1)\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission_obj_trainonly_vgg16_96.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(submission, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
